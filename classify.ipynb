{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Hymenoptera species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                                                                            #\n",
    "#                ▄▄████████████▄ ▐                                           #\n",
    "#             ▄███▀▀▀▀▀▀▀████████▐                                           #\n",
    "#         ▄▀▀▀▄▄▄▄███████▄▄▄▄▀▀▀█▐                                           #\n",
    "#      ▄▛ ▟█████████████████████▄▐                                           #\n",
    "#    ▄█▛ ▟█         ▀▚   █████   ▐                                           #\n",
    "#   ███ ██▌   ▄▄▄▖   ▐  ▐████▌   ▐    ████████ ████████  ▟████▙   ██     ██  #\n",
    "#  ████ ██▌   ███▛   ▐  ▐████▌   ▐       ██    ██       ▟█▛  ▜█▙  ██     ██  #\n",
    "#  ████ ▀█           ▞  █████    ▐       ██    ███████  ██        █████████  #\n",
    "#  █████ █   ▄▄▄▄▄▄▄▞   ▜██▛    ▐▐       ██    ██       ▜█▙  ▟█▛  ██     ██  #\n",
    "#   █████    ██████            ▐█▐       ██    ████████  ▜████▛   ██     ██  #\n",
    "#    █████  ███████▙          ▟██▐                                           #\n",
    "#     ▀████▙▀▀▀█████████████▀▀▀▄▄▐                                           #\n",
    "#       ▀██████▄▄▄▄▀▀▀▀▀▄▄▄▄█████▐                                           #\n",
    "#          ▀███████████████████▀ ▐                                           #\n",
    "#             ▀▀███████████▀▀    ▐                                           #\n",
    "#                                                                            #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./dataset/Hymenoptera.v2i.yolov5pytorch\"\n",
    "MODEL_PATH = \"./yolov5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Yolo model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'executer la commande, il faut clonner le projet yolov5 sur votre machine:   \n",
    "```bash\n",
    "git clone git@github.com:ultralytics/yolov5.git\n",
    "cd yolov5\n",
    "python train.py --img 640 --batch 16 --epochs 3 --data ../dataset/Hymenoptera.v2i.yolov5pytorch/data.yaml --weights yolov5m.pt --device cpu\n",
    "cd ..\n",
    "tensorboard --logdir yolov5/runs/train\n",
    "cd yolov5\n",
    "python export.py --weights ./runs/train/exp15/weights/best.pt --include tflite\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd yolov5\n",
    "!python detect.py --weights ./runs/train/exp15/weights/best.pt --source ../image/abeilles.jpg --output ../image/abeilles_detected.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# define EXT_TRAIN\n",
    "EXT_TRAIN = \"15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-10 15:16:29.431563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-10 15:16:29.452288: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sylvain/.pyenv/versions/3.8.9/envs/UseCase/lib/python3.8/site-packages/cv2/../../lib64:/usr/local/cuda-11.6/lib64:\n",
      "2022-02-10 15:16:29.452300: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-02-10 15:16:29.452598: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH + \"/runs/train/exp\"+EXT_TRAIN+\"/weights/best_saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frelon Europ-en',\n",
       " 'anthophila',\n",
       " 'vespa orientalis',\n",
       " 'vespa velutina',\n",
       " 'vespoidea']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get labels in data.yaml\n",
    "with open(DATA_PATH + \"/data.yaml\") as f:\n",
    "    data = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    labels = data[\"names\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image from disk\n",
    "image = cv2.imread('./image/abeilles.jpg')\n",
    "# preprocess the image for classification\n",
    "image_preprocessed = cv2.resize(image, (640, 640))\n",
    "image_preprocessed = image_preprocessed.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(np.expand_dims(image_preprocessed, axis=0))[0]\n",
    "# get best found class\n",
    "results = []\n",
    "for i in range(len(output)):\n",
    "    if output[i][4] > 0.5:\n",
    "        results.append(output[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    indice = np.argmax(result[5:10])\n",
    "    label = \"{}: {:.2f}%\".format(labels[4-indice], result[indice+5] * 100)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.17813344, 0.55643225, 0.3370436 , 0.62242335, 0.6598201 ,\n",
       "        0.00329047, 0.00472698, 0.00498188, 0.750872  , 0.4347657 ],\n",
       "       dtype=float32),\n",
       " array([0.18071966, 0.568867  , 0.339387  , 0.65152115, 0.8343003 ,\n",
       "        0.00375861, 0.00546089, 0.00482097, 0.67052007, 0.5111882 ],\n",
       "       dtype=float32),\n",
       " array([0.18426982, 0.5712788 , 0.3479124 , 0.64826554, 0.529524  ,\n",
       "        0.005263  , 0.01008776, 0.00778481, 0.71018445, 0.30698842],\n",
       "       dtype=float32),\n",
       " array([0.6941573 , 0.92268103, 0.44461986, 0.15436   , 0.5011538 ,\n",
       "        0.01192474, 0.00619721, 0.00391212, 0.7567251 , 0.44517294],\n",
       "       dtype=float32),\n",
       " array([0.1786963 , 0.5566897 , 0.344885  , 0.6235915 , 0.6539835 ,\n",
       "        0.00293434, 0.00529262, 0.00535089, 0.7144984 , 0.42759818],\n",
       "       dtype=float32),\n",
       " array([0.17970994, 0.5684565 , 0.35184672, 0.6479449 , 0.833331  ,\n",
       "        0.00319496, 0.00536299, 0.005032  , 0.63425493, 0.50386536],\n",
       "       dtype=float32),\n",
       " array([0.18437362, 0.5717573 , 0.3555564 , 0.64387167, 0.5560202 ,\n",
       "        0.0044089 , 0.00930601, 0.00748903, 0.69051456, 0.32432455],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 885, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17813344 0.55643225 0.3370436 0.62242335\n",
      "4 217 173 767\n",
      "0.18071966 0.568867 0.339387 0.65152115\n",
      "5 215 175 791\n",
      "0.18426982 0.5712788 0.3479124 0.64826554\n",
      "5 218 179 792\n",
      "0.6941573 0.92268103 0.44461986 0.15436\n",
      "235 748 458 884\n",
      "0.1786963 0.5566897 0.344885 0.6235915\n",
      "3 216 175 768\n",
      "0.17970994 0.5684565 0.35184672 0.6479449\n",
      "1 216 177 789\n",
      "0.18437362 0.5717573 0.3555564 0.64387167\n",
      "3 221 181 790\n"
     ]
    }
   ],
   "source": [
    "final_image = image.copy()\n",
    "\n",
    "for result in results:\n",
    "    # draw the box on the image\n",
    "    x, y, w, h = result[:4]\n",
    "    print(x, y, w, h)\n",
    "    startX = int((x - w / 2) * image.shape[0])\n",
    "    startY = int((y - h / 2) * image.shape[1])\n",
    "    endX = int((x + w / 2) * image.shape[0])\n",
    "    endY = int((y + h / 2) * image.shape[1])\n",
    "    print(startX, startY, endX, endY)\n",
    "\n",
    "    indice = np.argmax(result[5:])\n",
    "    label = \"{}: {:.2f}%\".format(labels[indice], result[indice+5] * 100)\n",
    "\n",
    "    final_image = cv2.rectangle(final_image, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "    # draw the predicted label on the image\n",
    "    final_image = cv2.putText(final_image, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", final_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([a.shape for a in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
    "# y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
    "# metrics.confusion_matrix(y_true, y_pred, labels=labels)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43f187d08a7b233672e80b21f375ffa49d1e0713ec8f6d0daf527eb8a4289c85"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
